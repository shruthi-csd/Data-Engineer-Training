{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#PySpark Setup & Initialization"
      ],
      "metadata": {
        "id": "Kv-qanuhyrjD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "t8m2FakIyI1O"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import *\n",
        "from pyspark.sql.window import Window"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spark = SparkSession.builder \\\n",
        "    .appName(\"BotCampus Intermediate Session\") \\\n",
        "    .master(\"local[*]\") \\\n",
        "    .getOrCreate()"
      ],
      "metadata": {
        "id": "or6xnutCyb-P"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = [(\"Ananya\", \"Bangalore\", 24),\n",
        "        (\"Ravi\", \"Hyderabad\", 28),\n",
        "        (\"Kavya\", \"Delhi\", 22),\n",
        "        (\"Meena\", \"Chennai\", 25)]\n",
        "columns = [\"name\", \"city\", \"age\"]\n",
        "df = spark.createDataFrame(data, columns)\n",
        "\n",
        "print(\"Starter DataFrame:\")\n",
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JC1IjxEnyg6T",
        "outputId": "9de13ec6-5fba-42f5-ea0a-6d5b1f6832d2"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starter DataFrame:\n",
            "+------+---------+---+\n",
            "|  name|     city|age|\n",
            "+------+---------+---+\n",
            "|Ananya|Bangalore| 24|\n",
            "|  Ravi|Hyderabad| 28|\n",
            "| Kavya|    Delhi| 22|\n",
            "| Meena|  Chennai| 25|\n",
            "+------+---------+---+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# RDDs & Transformations"
      ],
      "metadata": {
        "id": "5LlLj5KBy1_y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "feedback = spark.sparkContext.parallelize([\n",
        "    \"Ravi from Bangalore loved the mobile app\",\n",
        "    \"Meena from Delhi reported poor response time\",\n",
        "    \"Ajay from Pune liked the delivery speed\",\n",
        "    \"Ananya from Hyderabad had an issue with UI\",\n",
        "    \"Rohit from Mumbai gave positive feedback\"\n",
        "])"
      ],
      "metadata": {
        "id": "xCaKvXT6y5Iq"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word_count = feedback.flatMap(lambda line: line.split()).count()\n",
        "print(\"\\nTotal words:\", word_count)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g5p2tuyEy9ra",
        "outputId": "102b4985-08b0-49af-c204-819dfe1960fe"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Total words: 35\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stop_words = {\"from\", \"with\", \"the\", \"and\", \"an\"}\n",
        "words = feedback.flatMap(lambda line: line.lower().split()) \\\n",
        "                .filter(lambda w: w not in stop_words)\n",
        "word_freq = words.map(lambda w: (w, 1)).reduceByKey(lambda x, y: x+y)\n",
        "\n",
        "print(\"\\nWord Counts:\")\n",
        "for word, count in word_freq.collect():\n",
        "    print(word, \":\", count)\n",
        "\n",
        "top3 = word_freq.takeOrdered(3, key=lambda x: -x[1])\n",
        "print(\"\\nTop 3 words:\", top3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "anN6VmOrzBCL",
        "outputId": "5bdddf68-3e48-499c-802d-5599036c4237"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Word Counts:\n",
            "loved : 1\n",
            "app : 1\n",
            "poor : 1\n",
            "response : 1\n",
            "liked : 1\n",
            "speed : 1\n",
            "ananya : 1\n",
            "issue : 1\n",
            "rohit : 1\n",
            "mumbai : 1\n",
            "positive : 1\n",
            "feedback : 1\n",
            "ravi : 1\n",
            "bangalore : 1\n",
            "mobile : 1\n",
            "meena : 1\n",
            "delhi : 1\n",
            "reported : 1\n",
            "time : 1\n",
            "ajay : 1\n",
            "pune : 1\n",
            "delivery : 1\n",
            "hyderabad : 1\n",
            "had : 1\n",
            "ui : 1\n",
            "gave : 1\n",
            "\n",
            "Top 3 words: [('loved', 1), ('app', 1), ('poor', 1)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word_dict = dict(word_freq.collect())\n",
        "print(\"\\nWord → Count Dictionary:\", word_dict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xTdcB7j1zIgy",
        "outputId": "b8c08fe8-050f-45b0-825d-9f63de456eae"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Word → Count Dictionary: {'loved': 1, 'app': 1, 'poor': 1, 'response': 1, 'liked': 1, 'speed': 1, 'ananya': 1, 'issue': 1, 'rohit': 1, 'mumbai': 1, 'positive': 1, 'feedback': 1, 'ravi': 1, 'bangalore': 1, 'mobile': 1, 'meena': 1, 'delhi': 1, 'reported': 1, 'time': 1, 'ajay': 1, 'pune': 1, 'delivery': 1, 'hyderabad': 1, 'had': 1, 'ui': 1, 'gave': 1}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#DataFrames Transformations"
      ],
      "metadata": {
        "id": "-7wJ5O8vzSb4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scores = [(\"Ravi\", \"Math\", 88),\n",
        "          (\"Ananya\", \"Science\", 92),\n",
        "          (\"Kavya\", \"English\", 79),\n",
        "          (\"Ravi\", \"English\", 67),\n",
        "          (\"Neha\", \"Math\", 94),\n",
        "          (\"Meena\", \"Science\", 85)]\n",
        "columns = [\"name\", \"subject\", \"score\"]\n",
        "df_scores = spark.createDataFrame(scores, columns)"
      ],
      "metadata": {
        "id": "PZW6CzqxzM2R"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_scores = df_scores.withColumn(\n",
        "    \"grade\",\n",
        "    when(col(\"score\") >= 90, \"A\")\n",
        "    .when((col(\"score\") >= 80) & (col(\"score\") < 90), \"B\")\n",
        "    .when((col(\"score\") >= 70) & (col(\"score\") < 80), \"C\")\n",
        "    .otherwise(\"D\")\n",
        ")\n",
        "print(\"\\nExam Scores with Grades:\")\n",
        "df_scores.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Ih6-yWlzNMh",
        "outputId": "c2a6931b-8dfb-4c8c-b3b5-b0dc6147d28b"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Exam Scores with Grades:\n",
            "+------+-------+-----+-----+\n",
            "|  name|subject|score|grade|\n",
            "+------+-------+-----+-----+\n",
            "|  Ravi|   Math|   88|    B|\n",
            "|Ananya|Science|   92|    A|\n",
            "| Kavya|English|   79|    C|\n",
            "|  Ravi|English|   67|    D|\n",
            "|  Neha|   Math|   94|    A|\n",
            "| Meena|Science|   85|    B|\n",
            "+------+-------+-----+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nAverage Score per Subject:\")\n",
        "df_scores.groupBy(\"subject\").agg(avg(\"score\").alias(\"avg_score\")).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qs0wOZuXzNdi",
        "outputId": "d699b0ee-f238-4b92-974a-034c879c89df"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Average Score per Subject:\n",
            "+-------+---------+\n",
            "|subject|avg_score|\n",
            "+-------+---------+\n",
            "|Science|     88.5|\n",
            "|   Math|     91.0|\n",
            "|English|     73.0|\n",
            "+-------+---------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_scores = df_scores.withColumn(\n",
        "    \"difficulty\",\n",
        "    when(col(\"subject\").isin(\"Math\",\"Science\"), \"Difficult\").otherwise(\"Easy\")\n",
        ")\n"
      ],
      "metadata": {
        "id": "x4KMv5YCzN7h"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "windowSpec = Window.partitionBy(\"subject\").orderBy(col(\"score\").desc())\n",
        "df_scores = df_scores.withColumn(\"rank\", rank().over(windowSpec))\n",
        "print(\"\\nRanked Scores:\")\n",
        "df_scores.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZczpYqXJzpbI",
        "outputId": "1ef8e13e-fcea-42fc-ae5f-1fd1585305fc"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Ranked Scores:\n",
            "+------+-------+-----+-----+----------+----+\n",
            "|  name|subject|score|grade|difficulty|rank|\n",
            "+------+-------+-----+-----+----------+----+\n",
            "| Kavya|English|   79|    C|      Easy|   1|\n",
            "|  Ravi|English|   67|    D|      Easy|   2|\n",
            "|  Neha|   Math|   94|    A| Difficult|   1|\n",
            "|  Ravi|   Math|   88|    B| Difficult|   2|\n",
            "|Ananya|Science|   92|    A| Difficult|   1|\n",
            "| Meena|Science|   85|    B| Difficult|   2|\n",
            "+------+-------+-----+-----+----------+----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.types import StringType\n",
        "to_upper = udf(lambda x: x.upper(), StringType())\n",
        "df_scores = df_scores.withColumn(\"name_upper\", to_upper(col(\"name\")))\n",
        "print(\"\\nScores with Uppercase Names:\")\n",
        "df_scores.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EgWTvpfPztW3",
        "outputId": "b6e2a474-5569-4ddb-9771-368a5f24ad01"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Scores with Uppercase Names:\n",
            "+------+-------+-----+-----+----------+----+----------+\n",
            "|  name|subject|score|grade|difficulty|rank|name_upper|\n",
            "+------+-------+-----+-----+----------+----+----------+\n",
            "| Kavya|English|   79|    C|      Easy|   1|     KAVYA|\n",
            "|  Ravi|English|   67|    D|      Easy|   2|      RAVI|\n",
            "|  Neha|   Math|   94|    A| Difficult|   1|      NEHA|\n",
            "|  Ravi|   Math|   88|    B| Difficult|   2|      RAVI|\n",
            "|Ananya|Science|   92|    A| Difficult|   1|    ANANYA|\n",
            "| Meena|Science|   85|    B| Difficult|   2|     MEENA|\n",
            "+------+-------+-----+-----+----------+----+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ingest CSV & JSON  Save to Parquet\n"
      ],
      "metadata": {
        "id": "CsfERnsPz0_v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "data = [\n",
        "    [1, \"Amit\", \"IT\", \"Bangalore\", 78000],\n",
        "    [2, \"Kavya\", \"HR\", \"Chennai\", 62000],\n",
        "    [3, \"Arjun\", \"Finance\", \"Hyderabad\", 55000]\n",
        "]\n",
        "columns = [\"id\",\"name\",\"department\",\"city\",\"salary\"]\n",
        "\n",
        "df_pandas = pd.DataFrame(data, columns=columns)\n",
        "df_pandas.to_csv(\"students.csv\", index=False)\n",
        "\n",
        "df_csv = spark.read.csv(\"students.csv\", header=True, inferSchema=True)\n",
        "df_csv.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UcgBfu78135j",
        "outputId": "b9cc6070-434e-4b1f-efd1-84a63270c4be"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+-----+----------+---------+------+\n",
            "| id| name|department|     city|salary|\n",
            "+---+-----+----------+---------+------+\n",
            "|  1| Amit|        IT|Bangalore| 78000|\n",
            "|  2|Kavya|        HR|  Chennai| 62000|\n",
            "|  3|Arjun|   Finance|Hyderabad| 55000|\n",
            "+---+-----+----------+---------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_csv = spark.read.csv(\"students.csv\", header=True, inferSchema=True)\n",
        "print(\"\\nCSV Schema:\")\n",
        "df_csv.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eDIIL_Cdz6GA",
        "outputId": "4ae45210-731c-4bd6-b4f8-baa50e8fa4f5"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "CSV Schema:\n",
            "root\n",
            " |-- id: integer (nullable = true)\n",
            " |-- name: string (nullable = true)\n",
            " |-- department: string (nullable = true)\n",
            " |-- city: string (nullable = true)\n",
            " |-- salary: integer (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "\n",
        "data = [\n",
        "    {\n",
        "        \"id\": 101,\n",
        "        \"name\": \"Sneha\",\n",
        "        \"address\": {\n",
        "            \"city\": \"Mumbai\",\n",
        "            \"pincode\": 400001\n",
        "        },\n",
        "        \"skills\": [\"Python\", \"Spark\"]\n",
        "    }\n",
        "]\n",
        "\n",
        "\n",
        "with open(\"employee_nested.json\", \"w\") as f:\n",
        "    json.dump(data, f)\n",
        "\n",
        "\n",
        "df_json = spark.read.json(\"employee_nested.json\")\n",
        "df_json.show(truncate=False)\n",
        "df_json.printSchema()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-eaHO5XC2Ez4",
        "outputId": "324c9ca2-ad72-493b-c3c2-022b25851dfe"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------------+---+-----+---------------+\n",
            "|address         |id |name |skills         |\n",
            "+----------------+---+-----+---------------+\n",
            "|{Mumbai, 400001}|101|Sneha|[Python, Spark]|\n",
            "+----------------+---+-----+---------------+\n",
            "\n",
            "root\n",
            " |-- address: struct (nullable = true)\n",
            " |    |-- city: string (nullable = true)\n",
            " |    |-- pincode: long (nullable = true)\n",
            " |-- id: long (nullable = true)\n",
            " |-- name: string (nullable = true)\n",
            " |-- skills: array (nullable = true)\n",
            " |    |-- element: string (containsNull = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "df_json = spark.read.json(\"employee_nested.json\")\n",
        "print(\"\\nJSON Schema:\")\n",
        "df_json.printSchema()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3qOqhR1Xz_2v",
        "outputId": "2353e21c-c6b8-4b0d-dacf-e31bfea45319"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "JSON Schema:\n",
            "root\n",
            " |-- address: struct (nullable = true)\n",
            " |    |-- city: string (nullable = true)\n",
            " |    |-- pincode: long (nullable = true)\n",
            " |-- id: long (nullable = true)\n",
            " |-- name: string (nullable = true)\n",
            " |-- skills: array (nullable = true)\n",
            " |    |-- element: string (containsNull = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "df_flat = df_json.select(\n",
        "    \"id\",\n",
        "    \"name\",\n",
        "    col(\"address.city\").alias(\"city\"),\n",
        "    col(\"address.pincode\").alias(\"pincode\"),\n",
        "    explode(\"skills\").alias(\"skill\")\n",
        ")\n",
        "print(\"\\nFlattened JSON:\")\n",
        "df_flat.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LQtIWGmH0Dk3",
        "outputId": "a77476af-aa87-491b-fb32-e7d58d154c49"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Flattened JSON:\n",
            "+---+-----+------+-------+------+\n",
            "| id| name|  city|pincode| skill|\n",
            "+---+-----+------+-------+------+\n",
            "|101|Sneha|Mumbai| 400001|Python|\n",
            "|101|Sneha|Mumbai| 400001| Spark|\n",
            "+---+-----+------+-------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "df_csv.write.mode(\"overwrite\").parquet(\"/tmp/output/students\")\n",
        "df_flat.write.mode(\"overwrite\").parquet(\"/tmp/output/employees\")"
      ],
      "metadata": {
        "id": "c2_o2wIG0FWm"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Spark SQL Temp Views & Queries"
      ],
      "metadata": {
        "id": "K2yWCC6o2X_w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "df_scores.createOrReplaceTempView(\"exam_scores\")"
      ],
      "metadata": {
        "id": "2ZJwZbZB2dIC"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "spark.sql(\"\"\"\n",
        "SELECT subject, name, score\n",
        "FROM (\n",
        "  SELECT *, RANK() OVER(PARTITION BY subject ORDER BY score DESC) as rnk\n",
        "  FROM exam_scores\n",
        ")\n",
        "WHERE rnk=1\n",
        "\"\"\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p8F85qM42ljA",
        "outputId": "670769e1-af44-4a11-ac41-e15036799d2c"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+------+-----+\n",
            "|subject|  name|score|\n",
            "+-------+------+-----+\n",
            "|English| Kavya|   79|\n",
            "|   Math|  Neha|   94|\n",
            "|Science|Ananya|   92|\n",
            "+-------+------+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "spark.sql(\"SELECT grade, COUNT(*) as cnt FROM exam_scores GROUP BY grade\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X9a_tBiX2pwX",
        "outputId": "c282871d-46f1-4252-ff20-f6295a1e5611"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+---+\n",
            "|grade|cnt|\n",
            "+-----+---+\n",
            "|    B|  2|\n",
            "|    C|  1|\n",
            "|    A|  2|\n",
            "|    D|  1|\n",
            "+-----+---+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "spark.sql(\"\"\"\n",
        "SELECT name\n",
        "FROM exam_scores\n",
        "GROUP BY name\n",
        "HAVING COUNT(DISTINCT subject) > 1\n",
        "\"\"\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "968H5xMp2sJ4",
        "outputId": "e5b53a47-d08b-42fb-cb01-2f5a7ab63e7e"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+\n",
            "|name|\n",
            "+----+\n",
            "|Ravi|\n",
            "+----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "spark.sql(\"\"\"\n",
        "SELECT subject, AVG(score) as avg_score\n",
        "FROM exam_scores\n",
        "GROUP BY subject\n",
        "HAVING AVG(score)>85\n",
        "\"\"\").show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F6OQVc8f2s_Q",
        "outputId": "9158360b-af8f-4600-cdd6-6addedb1b223"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+---------+\n",
            "|subject|avg_score|\n",
            "+-------+---------+\n",
            "|Science|     88.5|\n",
            "|   Math|     91.0|\n",
            "+-------+---------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "attendance = [(\"Ravi\", 25), (\"Ananya\", 18), (\"Kavya\", 22), (\"Neha\", 20), (\"Meena\", 19)]\n",
        "df_attendance = spark.createDataFrame(attendance, [\"name\",\"days_present\"])\n",
        "\n",
        "df_joined = df_scores.join(df_attendance, \"name\", \"left\")"
      ],
      "metadata": {
        "id": "4L2FmYiT2vye"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def downgrade(grade):\n",
        "    mapping = {\"A\":\"B\",\"B\":\"C\",\"C\":\"D\",\"D\":\"D\"}\n",
        "    return mapping.get(grade,\"D\")\n",
        "\n",
        "downgrade_udf = udf(downgrade, StringType())\n",
        "df_final = df_joined.withColumn(\n",
        "    \"adj_grade\",\n",
        "    when(col(\"days_present\") < 20, downgrade_udf(col(\"grade\"))).otherwise(col(\"grade\"))\n",
        ")\n",
        "print(\"\\nAttendance-adjusted Grades:\")\n",
        "df_final.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kpCgVeol22BX",
        "outputId": "e7dc9bdc-7ecf-414d-94bd-43726dda2b15"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Attendance-adjusted Grades:\n",
            "+------+-------+-----+-----+----------+----+----------+------------+---------+\n",
            "|  name|subject|score|grade|difficulty|rank|name_upper|days_present|adj_grade|\n",
            "+------+-------+-----+-----+----------+----+----------+------------+---------+\n",
            "|Ananya|Science|   92|    A| Difficult|   1|    ANANYA|          18|        B|\n",
            "|  Ravi|English|   67|    D|      Easy|   2|      RAVI|          25|        D|\n",
            "|  Ravi|   Math|   88|    B| Difficult|   2|      RAVI|          25|        B|\n",
            "|  Neha|   Math|   94|    A| Difficult|   1|      NEHA|          20|        A|\n",
            "| Meena|Science|   85|    B| Difficult|   2|     MEENA|          19|        C|\n",
            "| Kavya|English|   79|    C|      Easy|   1|     KAVYA|          22|        C|\n",
            "+------+-------+-----+-----+----------+----+----------+------------+---------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Partitioned Load (Full + Incremental)"
      ],
      "metadata": {
        "id": "6i0QS3Lz3Pj-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_scores.write.partitionBy(\"subject\").mode(\"overwrite\").parquet(\"/tmp/scores/\")"
      ],
      "metadata": {
        "id": "mQ7cAmyU3PN_"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "incremental = [(\"Meena\", \"Math\", 93)]\n",
        "df_inc = spark.createDataFrame(incremental, [\"name\",\"subject\",\"score\"])\n",
        "df_inc.write.mode(\"append\").partitionBy(\"subject\").parquet(\"/tmp/scores/\")"
      ],
      "metadata": {
        "id": "d1DnmPNj3bZM"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import os\n",
        "print(\"\\nPartitions in /tmp/scores/:\", os.listdir(\"/tmp/scores/\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wq41CaGd3dOu",
        "outputId": "06ada452-a326-4f3f-d02c-53f3161d98a9"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Partitions in /tmp/scores/: ['._SUCCESS.crc', 'subject=Science', 'subject=English', '_SUCCESS', 'subject=Math']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "math_df = spark.read.parquet(\"/tmp/scores/subject=Math\")\n",
        "print(\"\\nMath Partition Data:\")\n",
        "math_df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uz8Rbbjm3eF2",
        "outputId": "9b8d8caf-6e73-4e05-c002-11c83be34af0"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Math Partition Data:\n",
            "+-----+-----+-----+----------+----+----------+\n",
            "| name|score|grade|difficulty|rank|name_upper|\n",
            "+-----+-----+-----+----------+----+----------+\n",
            "| Neha|   94|    A| Difficult|   1|      NEHA|\n",
            "| Ravi|   88|    B| Difficult|   2|      RAVI|\n",
            "|Meena|   93| NULL|      NULL|NULL|      NULL|\n",
            "+-----+-----+-----+----------+----+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ETL: Clean, Transform, Load"
      ],
      "metadata": {
        "id": "5DbUR4na3uVs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "data = [\n",
        "    [1, \"Arjun\", \"IT\", 78000, 5000],\n",
        "    [2, \"Kavya\", \"HR\", 62000, None],\n",
        "    [3, \"Sneha\", \"Finance\", 55000, 3000]\n",
        "]\n",
        "columns = [\"emp_id\",\"name\",\"dept\",\"salary\",\"bonus\"]\n",
        "\n",
        "\n",
        "df_pandas = pd.DataFrame(data, columns=columns)\n",
        "df_pandas.to_csv(\"raw_employees.csv\", index=False)\n",
        "\n",
        "df_emp = spark.read.csv(\"raw_employees.csv\", header=True, inferSchema=True)\n",
        "df_emp.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9z-LzGV64EvS",
        "outputId": "bd669cc7-5cfc-43c3-c250-1e10318265a3"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-----+-------+------+------+\n",
            "|emp_id| name|   dept|salary| bonus|\n",
            "+------+-----+-------+------+------+\n",
            "|     1|Arjun|     IT| 78000|5000.0|\n",
            "|     2|Kavya|     HR| 62000|  NULL|\n",
            "|     3|Sneha|Finance| 55000|3000.0|\n",
            "+------+-----+-------+------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_emp = spark.read.csv(\"raw_employees.csv\", header=True, inferSchema=True)"
      ],
      "metadata": {
        "id": "EOz-QdOW3rkr"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_emp = df_emp.fillna({\"bonus\":2000})\n"
      ],
      "metadata": {
        "id": "k9bqzKTA3032"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_emp = df_emp.withColumn(\"total_ctc\", col(\"salary\")+col(\"bonus\"))"
      ],
      "metadata": {
        "id": "JkYaxF-433iU"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_final = df_emp.filter(col(\"total_ctc\")>60000)\n",
        "print(\"\\nFiltered Employee Data:\")\n",
        "df_final.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yexXgssC36Uc",
        "outputId": "f1d6a543-5d30-473d-e03f-cbdfc66de877"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Filtered Employee Data:\n",
            "+------+-----+----+------+------+---------+\n",
            "|emp_id| name|dept|salary| bonus|total_ctc|\n",
            "+------+-----+----+------+------+---------+\n",
            "|     1|Arjun|  IT| 78000|5000.0|  83000.0|\n",
            "|     2|Kavya|  HR| 62000|2000.0|  64000.0|\n",
            "+------+-----+----+------+------+---------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_final.write.mode(\"overwrite\").parquet(\"/tmp/etl/employees_parquet\")\n",
        "df_final.write.mode(\"overwrite\").json(\"/tmp/etl/employees_json\")"
      ],
      "metadata": {
        "id": "hz_xvJOR38YM"
      },
      "execution_count": 40,
      "outputs": []
    }
  ]
}