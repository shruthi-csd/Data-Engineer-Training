{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d7e1f70d-0940-44f2-ab46-779da77eb1f7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We will store data in:\nLanding Orders folder:    dbfs:/FileStore/tables/dlt/landing/orders\nLanding Customers folder: dbfs:/FileStore/tables/dlt/landing/customers\nSilver Delta folder:      dbfs:/tmp/delta/sil_orders\nSQL Table name:           sil_orders_tbl\n"
     ]
    }
   ],
   "source": [
    "# STEP 0 — Setup\n",
    "# These variables store the paths for each stage of the pipeline\n",
    "\n",
    "# Landing folders: raw files exactly as they arrive\n",
    "LANDING_ORDERS    = \"dbfs:/FileStore/tables/dlt/landing/orders\"\n",
    "LANDING_CUSTOMERS = \"dbfs:/FileStore/tables/dlt/landing/customers\"\n",
    "\n",
    "# Silver folder: cleaned data in Delta format\n",
    "DELTA_SILVER_PATH = \"dbfs:/tmp/delta/sil_orders\"\n",
    "\n",
    "# SQL table name pointing to the silver Delta folder\n",
    "DELTA_TABLE_NAME  = \"sil_orders_tbl\"\n",
    "\n",
    "print(\"We will store data in:\")\n",
    "print(f\"Landing Orders folder:    {LANDING_ORDERS}\")\n",
    "print(f\"Landing Customers folder: {LANDING_CUSTOMERS}\")\n",
    "print(f\"Silver Delta folder:      {DELTA_SILVER_PATH}\")\n",
    "print(f\"SQL Table name:           {DELTA_TABLE_NAME}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f3dcdffb-4145-472f-a329-0aa7ab49492b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP 1: Seeding inline data to landing (JSON) ...\n✅ Seeded landing JSON:\n  dbfs:/FileStore/tables/dlt/landing/orders\n  dbfs:/FileStore/tables/dlt/landing/customers\n"
     ]
    }
   ],
   "source": [
    "from delta import *\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql import types as T\n",
    "\n",
    "print(\"STEP 1: Seeding inline data to landing (JSON) ...\")\n",
    "\n",
    "orders_rows = [\n",
    "    (1, \"C001\", \"2025-08-08 09:00:00\", 12000, \"placed\"),\n",
    "    (2, \"C002\", \"2025-08-08 09:05:00\",  4500, \"placed\"),\n",
    "    (3, \"C001\", \"2025-08-08 09:10:00\", 22000, \"cancelled\"),\n",
    "    (4, \"C003\", \"2025-08-08 09:15:00\",   800, \"placed\")\n",
    "]\n",
    "customers_rows = [\n",
    "    (\"C001\", \"Ananya\", \"Bengaluru\"),\n",
    "    (\"C002\", \"Rahul\",  \"Hyderabad\"),\n",
    "    (\"C003\", \"Meera\",  \"Pune\")\n",
    "]\n",
    "\n",
    "orders_schema = T.StructType([\n",
    "    T.StructField(\"order_id\",    T.IntegerType()),\n",
    "    T.StructField(\"customer_id\", T.StringType()),\n",
    "    T.StructField(\"order_ts\",    T.StringType()),\n",
    "    T.StructField(\"amount\",      T.IntegerType()),\n",
    "    T.StructField(\"status\",      T.StringType())\n",
    "])\n",
    "cust_schema = T.StructType([\n",
    "    T.StructField(\"customer_id\", T.StringType()),\n",
    "    T.StructField(\"name\",        T.StringType()),\n",
    "    T.StructField(\"city\",        T.StringType())\n",
    "])\n",
    "\n",
    "orders_df = (spark.createDataFrame(orders_rows, orders_schema)\n",
    "             .withColumn(\"order_ts\", F.to_timestamp(\"order_ts\")))\n",
    "customers_df = spark.createDataFrame(customers_rows, cust_schema)\n",
    "\n",
    "orders_df.write.mode(\"overwrite\").json(LANDING_ORDERS)\n",
    "customers_df.write.mode(\"overwrite\").json(LANDING_CUSTOMERS)\n",
    "\n",
    "print(\"✅ Seeded landing JSON:\")\n",
    "print(f\"  {LANDING_ORDERS}\")\n",
    "print(f\"  {LANDING_CUSTOMERS}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0712e3db-7b5c-41b0-9b19-e27490e4e6a4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**BRONZE DATA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9010b425-6779-47a3-81dd-c770686e3a61",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP 2: BRONZE - Reading raw landing data\nBronze Orders - schema & sample: \nroot\n |-- amount: long (nullable = true)\n |-- customer_id: string (nullable = true)\n |-- order_id: long (nullable = true)\n |-- order_ts: string (nullable = true)\n |-- status: string (nullable = true)\n\n+------+-----------+--------+------------------------+---------+\n|amount|customer_id|order_id|order_ts                |status   |\n+------+-----------+--------+------------------------+---------+\n|22000 |C001       |3       |2025-08-08T09:10:00.000Z|cancelled|\n|12000 |C001       |1       |2025-08-08T09:00:00.000Z|placed   |\n|4500  |C002       |2       |2025-08-08T09:05:00.000Z|placed   |\n|800   |C003       |4       |2025-08-08T09:15:00.000Z|placed   |\n+------+-----------+--------+------------------------+---------+\n\nBronze Customers - schema & sample: \nroot\n |-- city: string (nullable = true)\n |-- customer_id: string (nullable = true)\n |-- name: string (nullable = true)\n\n+---------+-----------+------+\n|city     |customer_id|name  |\n+---------+-----------+------+\n|Bengaluru|C001       |Ananya|\n|Hyderabad|C002       |Rahul |\n|Pune     |C003       |Meera |\n+---------+-----------+------+\n\n"
     ]
    }
   ],
   "source": [
    "print(\"STEP 2: BRONZE - Reading raw landing data\")\n",
    "\n",
    "bron_orders = spark.read.json(LANDING_ORDERS)\n",
    "bron_customers = spark.read.json(LANDING_CUSTOMERS)\n",
    "\n",
    "print(\"Bronze Orders - schema & sample: \")\n",
    "bron_orders.printSchema()\n",
    "bron_orders.show(truncate=False)\n",
    "\n",
    "print(\"Bronze Customers - schema & sample: \")\n",
    "bron_customers.printSchema()\n",
    "bron_customers.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "27b11195-acbd-4070-bef5-c88bc6c81f30",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**SILVER DATA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5c4beaff-176c-4496-b432-f566210595b8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 3: SILVER - Cleaning data & Writing to Delta\nWrote silver orders to delta path: \n dbfs:/tmp/delta/sil_orders\nReading back from delta to verify: \n+--------+-----------+------------------------+------+---------+\n|order_id|customer_id|order_ts                |amount|status   |\n+--------+-----------+------------------------+------+---------+\n|3       |C001       |2025-08-08T09:10:00.000Z|22000 |cancelled|\n|1       |C001       |2025-08-08T09:00:00.000Z|12000 |placed   |\n|4       |C003       |2025-08-08T09:15:00.000Z|800   |placed   |\n|2       |C002       |2025-08-08T09:05:00.000Z|4500  |placed   |\n+--------+-----------+------------------------+------+---------+\n\n"
     ]
    }
   ],
   "source": [
    "print(\"Step 3: SILVER - Cleaning data & Writing to Delta\")\n",
    "\n",
    "sil_orders = (\n",
    "    bron_orders\n",
    "    .select(\"order_id\", \"customer_id\", \"order_ts\", \"amount\", \"status\")\n",
    "    .filter(\"order_id IS NOT NULL AND amount >= 0\")\n",
    ")\n",
    "\n",
    "sil_orders.write.format(\"delta\").mode(\"overwrite\").save(DELTA_SILVER_PATH)\n",
    "\n",
    "print(\"Wrote silver orders to delta path: \")\n",
    "print(f\" {DELTA_SILVER_PATH}\")\n",
    "\n",
    "print(\"Reading back from delta to verify: \")\n",
    "spark.read.format(\"delta\").load(DELTA_SILVER_PATH).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9fedea62-750f-4f28-9e49-efaa665873a6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP 5: GOLD - Enrich orders by joining with customers\nGold Enriched - sample:\n+-----------+--------+------------------------+------+---------+---------+------+\n|customer_id|order_id|order_ts                |amount|status   |city     |name  |\n+-----------+--------+------------------------+------+---------+---------+------+\n|C001       |3       |2025-08-08T09:10:00.000Z|22000 |cancelled|Bengaluru|Ananya|\n|C001       |1       |2025-08-08T09:00:00.000Z|12000 |placed   |Bengaluru|Ananya|\n|C003       |4       |2025-08-08T09:15:00.000Z|800   |placed   |Pune     |Meera |\n|C002       |2       |2025-08-08T09:05:00.000Z|4500  |placed   |Hyderabad|Rahul |\n+-----------+--------+------------------------+------+---------+---------+------+\n\n"
     ]
    }
   ],
   "source": [
    "print(\"STEP 5: GOLD - Enrich orders by joining with customers\")\n",
    "\n",
    "sil_orders_df = spark.read.format(\"delta\").load(DELTA_SILVER_PATH)\n",
    "gold_enriched = (\n",
    "    sil_orders_df.alias(\"o\")\n",
    "    .join(bron_customers.alias(\"c\"), on=\"customer_id\", how=\"left\")\n",
    ")\n",
    "\n",
    "print(\"Gold Enriched - sample:\")\n",
    "gold_enriched.show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a2d0eea2-370e-434d-a2b2-0b5e1f189bea",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After UPDATE:\n+--------+-----------+--------------------+------+-------+\n|order_id|customer_id|            order_ts|amount| status|\n+--------+-----------+--------------------+------+-------+\n|       1|       C001|2025-08-08T09:00:...| 12000|shipped|\n|       4|       C003|2025-08-08T09:15:...|   800| placed|\n|       2|       C002| 2025-08-08 10:00:00|  4800|shipped|\n|       5|       C004| 2025-08-08 10:05:00|  7000|shipped|\n+--------+-----------+--------------------+------+-------+\n\nAfter DELETE:\n+--------+-----------+--------------------+------+-------+\n|order_id|customer_id|            order_ts|amount| status|\n+--------+-----------+--------------------+------+-------+\n|       1|       C001|2025-08-08T09:00:...| 12000|shipped|\n|       4|       C003|2025-08-08T09:15:...|   800| placed|\n|       2|       C002| 2025-08-08 10:00:00|  4800|shipped|\n|       5|       C004| 2025-08-08 10:05:00|  7000|shipped|\n+--------+-----------+--------------------+------+-------+\n\nAfter UPSERT:\n+--------+-----------+--------------------+------+-------+\n|order_id|customer_id|            order_ts|amount| status|\n+--------+-----------+--------------------+------+-------+\n|       1|       C001|2025-08-08T09:00:...| 12000|shipped|\n|       4|       C003|2025-08-08T09:15:...|   800| placed|\n|       2|       C002| 2025-08-08 10:00:00|  4800|shipped|\n|       5|       C004| 2025-08-08 10:05:00|  7000| placed|\n+--------+-----------+--------------------+------+-------+\n\n"
     ]
    }
   ],
   "source": [
    "from delta.tables import DeltaTable\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql import Row\n",
    "\n",
    "# Load the Delta table as a DeltaTable object\n",
    "delta_table = DeltaTable.forPath(spark, DELTA_SILVER_PATH)\n",
    "\n",
    "#UPDATE — change 'status' to 'shipped' for placed orders with amount > 5000\n",
    "\n",
    "delta_table.update(\n",
    "    condition=\"status = 'placed' AND amount > 5000\",\n",
    "    set={\n",
    "        \"status\": F.lit(\"shipped\")\n",
    "    }\n",
    ")\n",
    "\n",
    "print(\"After UPDATE:\")\n",
    "delta_table.toDF().show()\n",
    "\n",
    "# DELETE — remove cancelled orders\n",
    "\n",
    "delta_table.delete(\"status = 'cancelled'\")\n",
    "\n",
    "print(\"After DELETE:\")\n",
    "delta_table.toDF().show()\n",
    "\n",
    "# UPSERT (MERGE) — insert new orders or update existing ones\n",
    "\n",
    "new_orders = [\n",
    "    Row(order_id=2, customer_id=\"C002\", order_ts=\"2025-08-08 10:00:00\", amount=4800, status=\"shipped\"),\n",
    "    Row(order_id=5, customer_id=\"C004\", order_ts=\"2025-08-08 10:05:00\", amount=7000, status=\"placed\")\n",
    "]\n",
    "new_df = spark.createDataFrame(new_orders) \\\n",
    "              .withColumn(\"order_ts\", F.to_timestamp(\"order_ts\"))\n",
    "\n",
    "# Perform merge (upsert)\n",
    "delta_table.alias(\"target\").merge(\n",
    "    new_df.alias(\"source\"),\n",
    "    \"target.order_id = source.order_id\"\n",
    ").whenMatchedUpdateAll() \\\n",
    " .whenNotMatchedInsertAll() \\\n",
    " .execute()\n",
    "\n",
    "print(\"After UPSERT:\")\n",
    "delta_table.toDF().show()\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Landing",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}